{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737bf7fb-951f-4984-8a7c-9d65aa72921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "\n",
    "In machine learning, the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernelized models, that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables, allowing learning of non-linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab62871-d203-48f5-9f8a-23363f3a22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm_poly = SVC(kernel='poly', degree=3)  \n",
    "\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of SVM with polynomial kernel: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b8295-1344-484e-a7b3-96df3a9225dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "In Support Vector Regression (SVR), the parameter \n",
    "\n",
    "系 defines the width of the tube within which no penalty is associated with errors. This parameter influences the number of support vectors and the behavior of the SVR model. Heres how increasing the value of \n",
    "\n",
    "系 affects the number of support vectors:\n",
    "\n",
    "Impact on Tube Width:\n",
    "\n",
    "\n",
    "系 determines the size of the 蔚-insensitive tube around the regression line (or hyperplane in higher dimensions). Data points within this tube do not contribute to the loss function and are effectively ignored by the model.\n",
    "Increasing \n",
    "\n",
    "系 widens this tube, allowing more data points to fall within it without affecting the model's performance.\n",
    "Effect on Support Vectors:\n",
    "\n",
    "Support vectors are data points that lie on the boundaries of the 蔚-insensitive tube or are within the tube. They are crucial for defining the regression line or hyperplane.\n",
    "When \n",
    "\n",
    "系 is small, the 蔚-insensitive tube is narrow, and fewer points can be within this tolerance. Therefore, more data points may become support vectors as the model tries to fit the training data more closely.\n",
    "Conversely, as \n",
    "\n",
    "系 increases, more data points can lie within the 蔚-insensitive tube without penalty, potentially reducing the number of support vectors.\n",
    "Model Complexity and Generalization:\n",
    "\n",
    "Smaller values of \n",
    "\n",
    "系 lead to a more complex model with potentially more support vectors, as it tries to fit the training data closely.\n",
    "Larger values of \n",
    "\n",
    "系 promote a simpler model with fewer support vectors, as it allows more points to be considered non-support vectors within the tolerance zone, focusing less on fitting every training point precisely.\n",
    "Trade-off in Model Performance:\n",
    "\n",
    "Choosing an appropriate value for \n",
    "\n",
    "系 involves a trade-off between model complexity and generalization ability.\n",
    "A smaller \n",
    "\n",
    "系 might lead to overfitting if the model captures noise in the training data, while a larger \n",
    "\n",
    "系 might result in underfitting if it ignores important patterns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b0cc3-817f-4e59-a4f9-05e6296b757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
